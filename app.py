import streamlit as st
import google.generativeai as genai
from google.api_core import exceptions
from PIL import Image
import time
import os

# ---------------------------------------------------------
# è¨­å®šãƒ»é–¢æ•°å®šç¾©
# ---------------------------------------------------------
st.set_page_config(page_title="TTV Quality Gatekeeper", page_icon="ğŸ›¡ï¸", layout="wide")

def load_knowledge_base():
    try:
        with open("knowledge_base.txt", "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return "ã‚¨ãƒ©ãƒ¼ï¼šknowledge_base.txt ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"

# ---------------------------------------------------------
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šèªè¨¼ & è¨­å®š
# ---------------------------------------------------------
with st.sidebar:
    st.header("èªè¨¼è¨­å®š")
    user_password = st.text_input("ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼", type="password")
    if user_password != st.secrets["APP_PASSWORD"]:
        st.warning("âš ï¸ æ­£ã—ã„ã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        st.stop()
    
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    st.success("èªè¨¼æˆåŠŸ")
    
    st.divider()
    with st.expander("ç¾åœ¨ã®ãƒã‚§ãƒƒã‚¯ãƒ«ãƒ¼ãƒ«"):
        st.text(load_knowledge_base())
    
    # å±¥æ­´ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³ï¼ˆãƒãƒ£ãƒƒãƒˆç”¨ï¼‰
    if st.button("ğŸ—‘ï¸ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’æ¶ˆå»"):
        st.session_state.messages = []
        st.rerun()

# ---------------------------------------------------------
# ãƒ¡ã‚¤ãƒ³ç”»é¢ï¼šã‚¿ãƒ–åˆ‡ã‚Šæ›¿ãˆ
# ---------------------------------------------------------
st.title("ğŸ›¡ï¸ TTV Quality Gatekeeper")
st.info("""
TTVã®æœ€æ–°å±æ©Ÿç®¡ç†è¦å®šã«åŸºãã€å‹•ç”»ãƒ»ç”»åƒã®ãƒã‚§ãƒƒã‚¯ãŠã‚ˆã³ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ç›¸è«‡ã‚’è¡Œã„ã¾ã™ã€‚
â€»AIã®åˆ¤å®šã¯æ”¯æ´æƒ…å ±ã§ã™ã€‚æœ€çµ‚åˆ¤æ–­ã¯å¿…ãšäººé–“ãŒè¡Œã£ã¦ãã ã•ã„ã€‚
""")

# ã‚¿ãƒ–ã®ä½œæˆ
tab1, tab2 = st.tabs(["ğŸ“ ç´ æãƒã‚§ãƒƒã‚¯ (å‹•ç”»/ç”»åƒ)", "ğŸ’¬ ã‚³ãƒ³ãƒ—ãƒ©ç›¸è«‡ãƒãƒ£ãƒƒãƒˆ"])

# =========================================================
# ã‚¿ãƒ–1ï¼šç´ æãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ (å‹•ç”» & ç”»åƒ)
# =========================================================
with tab1:
    st.subheader("ãƒ¡ãƒ‡ã‚£ã‚¢å“è³ªãƒã‚§ãƒƒã‚¯")
    uploaded_file = st.file_uploader(
        "ãƒã‚§ãƒƒã‚¯ã—ãŸã„ãƒ•ã‚¡ã‚¤ãƒ« (MP4, MOV, JPG, PNG) ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", 
        type=["mp4", "mov", "jpg", "jpeg", "png", "webp"]
    )

    if uploaded_file is not None:
        file_type = uploaded_file.type
        
        # --- ç”»åƒã®å ´åˆ ---
        if "image" in file_type:
            image = Image.open(uploaded_file)
            st.image(image, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ", use_column_width=True)
            
            if st.button("ğŸš€ ç”»åƒãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ", type="primary"):
                with st.spinner("ç”»åƒå†…ã®æ–‡å­—ã¨æå†™ã‚’è§£æä¸­..."):
                    try:
                        current_knowledge = load_knowledge_base()
                        model = genai.GenerativeModel(model_name="gemini-flash-latest")
                        
                        prompt = f"""
                        ã‚ãªãŸã¯TTVã®å³æ ¼ãªæ ¡é–²ãƒ»ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹æ‹…å½“AIã§ã™ã€‚
                        ä»¥ä¸‹ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã«åŸºã¥ãã€ç”»åƒå†…ã®ã€Œæ–‡å­—ï¼ˆãƒ†ãƒ­ãƒƒãƒ—ï¼‰ã€ã¨ã€Œæå†™ã€ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚

                        â– ãƒã‚§ãƒƒã‚¯é …ç›®
                        1. èª¤å­—è„±å­—ã€å¸¸ç”¨æ¼¢å­—ä»¥å¤–ã®ä½¿ç”¨ï¼ˆã€Œè‹ºã€ã€Œç¶ºéº—ã€ãªã©ï¼‰
                        2. ä¸é©åˆ‡ãªç”»åƒè¡¨ç¾ã€ãƒªã‚¹ã‚¯ã®ã‚ã‚‹æ˜ ã‚Šè¾¼ã¿
                        3. ãã®ä»–ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã¸ã®é•å

                        â– ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹
                        {current_knowledge}

                        â– å‡ºåŠ›
                        å•é¡Œç‚¹ã®ã¿ã‚’ç®‡æ¡æ›¸ãã§æŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚å•é¡Œãªã‘ã‚Œã°ã€ŒæŒ‡æ‘˜äº‹é …ãªã—ã€ã¨ã—ã¦ãã ã•ã„ã€‚
                        """
                        
                        # ç”»åƒè§£æå®Ÿè¡Œ
                        response = model.generate_content([image, prompt])
                        
                        st.success("è§£æå®Œäº†")
                        st.markdown("### ğŸ“Š ç”»åƒåˆ¤å®šãƒ¬ãƒãƒ¼ãƒˆ")
                        st.markdown(response.text)
                        
                    except Exception as e:
                        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

        # --- å‹•ç”»ã®å ´åˆ ---
        elif "video" in file_type:
            st.video(uploaded_file)
            
            if st.button("ğŸš€ å‹•ç”»ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ", type="primary"):
                status_text = st.empty()
                progress_bar = st.progress(0)

                try:
                    current_knowledge = load_knowledge_base()
                    
                    # ä¿å­˜ã¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                    status_text.text("AIã‚µãƒ¼ãƒãƒ¼ã¸è»¢é€ä¸­...")
                    progress_bar.progress(20)
                    temp_file_path = "temp_video.mp4"
                    with open(temp_file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    
                    video_file = genai.upload_file(path=temp_file_path)

                    # å‡¦ç†å¾…ã¡
                    while video_file.state.name == "PROCESSING":
                        status_text.text("æ˜ åƒå‡¦ç†ä¸­... (æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)")
                        time.sleep(2)
                        video_file = genai.get_file(video_file.name)

                    if video_file.state.name == "FAILED":
                        st.error("å‹•ç”»å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                        st.stop()

                    # è§£æå®Ÿè¡Œ
                    status_text.text("ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã¨ç…§åˆä¸­...")
                    progress_bar.progress(60)
                    
                    model = genai.GenerativeModel(model_name="gemini-flash-latest")
                    
                    prompt = f"""
                    ã‚ãªãŸã¯TTVã®å³æ ¼ãªæ ¡é–²ãƒ»ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹æ‹…å½“AIã§ã™ã€‚
                    ä»¥ä¸‹ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã«åŸºã¥ãå‹•ç”»ã‚’è§£æã—ã¦ãã ã•ã„ã€‚

                    â– ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹
                    {current_knowledge}

                    â– å‡ºåŠ›å½¢å¼ (Markdownãƒ†ãƒ¼ãƒ–ãƒ«)
                    | ã‚¿ã‚¤ãƒ ã‚³ãƒ¼ãƒ‰ | åˆ¤å®š(NG/æ³¨æ„) | æŒ‡æ‘˜å†…å®¹ | è©²å½“ãƒŠãƒ¬ãƒƒã‚¸ |
                    | :--- | :--- | :--- | :--- |
                    """

                    try:
                        response = model.generate_content([video_file, prompt])
                    except exceptions.ResourceExhausted:
                        status_text.warning("âš ï¸ ã‚¢ã‚¯ã‚»ã‚¹é›†ä¸­ã€‚30ç§’å¾…æ©Ÿã—ã¦å†è©¦è¡Œã—ã¾ã™...")
                        time.sleep(30)
                        status_text.text("å†è©¦è¡Œä¸­...")
                        response = model.generate_content([video_file, prompt])
                    
                    progress_bar.progress(100)
                    status_text.text("å®Œäº†")
                    
                    st.divider()
                    st.markdown("### ğŸ“Š å‹•ç”»åˆ¤å®šãƒ¬ãƒãƒ¼ãƒˆ")
                    st.markdown(response.text)

                    # æƒé™¤
                    genai.delete_file(video_file.name)
                    os.remove(temp_file_path)

                except Exception as e:
                    st.error(f"ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")

# =========================================================
# ã‚¿ãƒ–2ï¼šã‚³ãƒ³ãƒ—ãƒ©ç›¸è«‡ãƒãƒ£ãƒƒãƒˆ
# =========================================================
with tab2:
    st.subheader("ğŸ’¬ AIã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ç›¸è«‡å®¤")
    st.caption("ã€Œã“ã®è¡¨ç¾ã¯å¤§ä¸ˆå¤«ï¼Ÿã€ã€Œå¸¸ç”¨æ¼¢å­—ã‹æ•™ãˆã¦ã€ãªã©ã€åˆ¶ä½œä¸­ã®ç–‘å•ã‚’AIã«ç›¸è«‡ã§ãã¾ã™ã€‚")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # å±¥æ­´ã®è¡¨ç¤º
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
    if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # AIã®å›ç­”ç”Ÿæˆ
        with st.chat_message("assistant"):
            try:
                current_knowledge = load_knowledge_base()
                model = genai.GenerativeModel(model_name="gemini-flash-latest")
                
                # ãƒãƒ£ãƒƒãƒˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’èƒŒæ™¯çŸ¥è­˜ã¨ã—ã¦æŒãŸã›ã‚‹ï¼‰
                system_instruction = f"""
                ã‚ãªãŸã¯TTVã®æ”¾é€è¦å®šã«è©³ã—ã„ã€Œã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ãƒ»ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã€ã§ã™ã€‚
                ä»¥ä¸‹ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ï¼ˆè¦å®šï¼‰ã‚’ç†ŸçŸ¥ã—ã¦ã„ã¾ã™ã€‚
                ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã€ã“ã®è¦å®šã«åŸºã¥ã„ã¦çš„ç¢ºã«ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã—ã¦ãã ã•ã„ã€‚
                è¦å®šã«ãªã„ã“ã¨ã§ã‚‚ã€ä¸€èˆ¬çš„ãªæ”¾é€å€«ç†ã‚„ãƒªã‚¹ã‚¯ç®¡ç†ã®è¦³ç‚¹ã‹ã‚‰å›ç­”ã—ã¦ãã ã•ã„ã€‚
                
                â– ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹
                {current_knowledge}
                """
                
                # ä¼šè©±å±¥æ­´ã‚’å«ã‚ã¦é€ä¿¡ï¼ˆæ–‡è„ˆç¶­æŒã®ãŸã‚ï¼‰
                chat = model.start_chat(history=[])
                # â€»ç°¡æ˜“åŒ–ã®ãŸã‚ã€æ¯å›ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ+ç›´è¿‘ã®è³ªå•ã§å•ã„åˆã‚ã›ã‚‹å½¢å¼ã«ã—ã¾ã™
                full_prompt = f"{system_instruction}\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}"
                
                response = model.generate_content(full_prompt)
                
                st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
                
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
